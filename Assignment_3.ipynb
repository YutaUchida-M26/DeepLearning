{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3.\n",
    "\n",
    "## Student Name/ID: YutaUchida / m5261176\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Convolutional Neural network using PyTorch\n",
    "\n",
    "The aim of this assignment is to create improved version, comparing to the one used in exercise 3, using PyTorch library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2)  # we set up a seed so that your output matches ours although the initialization is random.\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to define helper functions to load data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    train_dataset = h5py.File('./datasets/train_signs.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:])  # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:])  # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('./datasets/test_signs.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:])  # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:])  # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:])  # the list of classes\n",
    "\n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "\n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data (signs)\n",
    "train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will use the same dataset as in the exercise 3. \n",
    "\n",
    "The SIGNS dataset is a collection of 6 signs representing numbers from 0 to 5.\n",
    "\n",
    "The next cell will show you an example of a labelled image in the dataset. Feel free to change the value of `index` below and re-run to see different examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyaElEQVR4nO19a4xcx5Xed/oxPS8OZ/gekZRESdSTFimLki3Llmk9HPkBa/PDm/VmF0ogQH+cwItssJITIMAGCKAgwGLzIwggZB0LWO96Fa9t0Y5jW6YsP/SmrPeDIkVRJMUhh+TMcN7TM92VH928dU7drpqanmE31/d8wGDq3qpbVX37Vt9z6pzzHTLGQKFQ/P4j1+4JKBSK1kAXu0KREehiVygyAl3sCkVGoItdocgIdLErFBnBshY7Ed1LRAeI6BARPbxSk1IoFCsPatbOTkR5AO8BuAfAcQAvAfiaMebtlZueQqFYKRSWce2tAA4ZYw4DABF9F8B9ALyLfc2aAbN18+baAS1j5BXF8idCgS5SP6XN/LauwL1aWhet/HKWfkOCV1xwH7ELMMAKdGnqnRz/6ARGRkYbfoHLWeybARxjx8cBfCJ0wdbNm/HTvY/XDtzpUKxGQQ2LqcPUx238AFNopUbOI92FPeF+j2FBilfyz+kOYLx15OsiNVboPnruSehWNf3AmoZFADDka+Y2ZEVTDYzEGwbuaWCK4XZVf6vAFx8vXXtuCOvji/f9offq5ejsjb761KyJ6EEi2k9E+8+OjCxjOIVCsRws581+HMBWdrwFwAm3kTHmUQCPAsDOj+3gryRvx+4vBnlrAzWBH0v+MnR/VEm8lUOdhN4SgSrfqzfUT2qS/AOEm/qGEofhG+5vF43I7yzwsm12byn2pdxOcOlSfs4lSJ0RTZfzZn8JwHYi2kZEHQD+CMDeZfSnUCguIJp+sxtjFojo3wD4GYA8gG8ZY95asZkpFIoVxXLEeBhjfgLgJys0F4VCcQGxrMW+kgjpZNF7lcGddcNKof2CuHbBSfk3TYVi6u56y7Gb0934LYjdPE+rypGKfxC+PpbwPXv3DpydaHGNa51g9zSw1xH+0nzfi2wavN+h7qPvFXnK9shrSYG6yyoUmYEudoUiI2ixGG+iRMRYCTndvUdkazCP5kaI9liJ6sIE7IMUeT/S3TeeY3qKkeqK55p0n65tr7F9c0nWLymf29MpvYM3DI0QVl68XQgR3H0/+j6bc68M/z7dliEHLd7OXpd+dIzzPw19sysUGYEudoUiI9DFrlBkBC03vZ03sYXMTikIi0lz+mVYf10e0i63fn04aIGJHs9v72lG13fNnr7745o2pUrtBmYs3l9qHhFnan37zV9hfbu5b14O5zfLBftYCRftiO82tD70za5QZAS62BWKjKDlYvx5ISMtroS82jyx6MH4Z0d8FmJUIFY8GF3lUQXcLiKP0qrM4uOmEIqIiwSl7DiNzYrBbywlmjbGkuK8I9s1p5cFVIFU9yEx21Nn/N9tkJ5AvH9jn6Q46JtdocgIdLErFBlBG3bjPedDMQoeT6ownVKkiBy5E+32IokyQswQMb01qouVTQNqSGAHmNflAswWwV31kC4jphTbiet1xmtCO9GRClDk/Qg9gGHhOeBVyb0Ig534abX4IkkHvJy3cvmhb3aFIiPQxa5QZAS62BWKjKClOrtBSHdm5WZd3CKDmoJdNBHMFiI0SJEpBKfUBOFkai6ND8KxfCHzV2DGTdzvsL7q7h0EItEiEW2+CyKk7C+5hwb7Mc3OyzdCY+ibXaHICHSxKxQZQetNbxEiiwlk65A0YkvwLGOgkMmIkww0Z1ELziPIg+aPQAl16UXsULHTCKkdKfNjtF4W+DBROl+4ixAnhb8P1xzbhMdliCcvOHSzAVsqxisUijp0sSsUGYEudoUiI2i9zl6tayiu7hMgX/TpuRTShGLNU+5lASXPT2K5BH01YNsj4VYaR0Lhklb6yCuCHI1BS1Cc/S5NougbbClo/L0HTZ0XACZS8Y/NRxezb7V4H0s7D0S82YnoW0Q0TERvsnNriOhJIjpY/z+w1MkqFIrWIkaM/zaAe51zDwPYZ4zZDmBf/VihUFzEWFSMN8b8mogud07fB2BPvfwYgKcBPBQ35OImglDUm7TwuH35+/YTLQRMY6l5+ISkJm10KfOMz+wSEpGdLoWZ0q8KhIgnQnQbsVgRydrbyfI90NIitz9iUrZa/icLk5aEIvhiueoao9kNuo3GmCEAqP/f0GQ/CoWiRbjgu/FE9CAR7Sei/SMjoxd6OIVC4UGzu/GniGjQGDNERIMAhn0NjTGPAngUAG782A3Giimx/GsBQTIlicXtpAeFUc+OuHulnFMoQKRZsc9eVw3yrwUCbUxjkV723qhPXox7H4Q/ZeTW/1KCZHxVKe63xp3G8/9JpLwqV0JfaWIXvxlFptk3+14A99fL9wN4osl+FApFixBjevt7AM8BuIaIjhPRAwAeAXAPER0EcE/9WKFQXMSI2Y3/mqfqrhWei0KhuIBouQedRUqptuWAHhrSTlxfMnEUnc7Z36PUPJn+XlkQ7apzM0k5V+qU8yh0RI0n0/g2t78hzrvEmkIvj/M2DN21sA4Ze2XICMV1+5B5Kq73Jana4ibEeksGntNoj8J4U+f5fSMlnFQoFLrYFYqsoLVivDGomhovdsqkI2i+HO5ssm2FdS1kBnHjT5x5+BrGCWJAtTyblM++/CtRVzl1LCnn+9eLutU7b0vKpTUbZac+sokl8Ttw80yIx9xP0uEffAXYPFYgXVWw+2Bl6NuN/JzR3oYrgXDI1lKhb3aFIiPQxa5QZAS62BWKjKCNvPF+01taF298VVoN9fN7RxNV+kPsxIAjRw4l5WPP/1Y06+0oJeXCaRkPMDV2LikP3vUVUdfR199wGmH1LM6ldymuxT5d33U9TZNMNkaY/CHOkBhtrYpsGDagOZr4irjExlbG3lOJGLddfbMrFBmBLnaFIiNovQfdeZko5RUWEPU8hBVpsZIfhLjWuVrgklfwkfxeeBPnxpLy6dFzol25qycp93aLKhROnUzKJ174pajbcscXknKeed4FxeXo8KeAaJriA2zcMBUpFpIdPV9n6pOIdtGyujxqRsR35278z1X8XGJNey4af7/BKzwmwNA1+mZXKDICXewKRUbQhvRPbqEByBXTOAkD/33yB4hE7renJxIpzq3ecnlSnu1wZPUZGwgDyouqXjb9hfffFXXD/WuS8qabP82mJPsQm+VNEj64wTUcPpKEJW2k+/oOcloHrouX1Z1jT0DRkuYet0MeMAZhkTu5ZARVWA/0za5QZAS62BWKjEAXu0KREbTB9Fb/F2m2CVc6prGAV5gvuirtTddYX3Xb9m2wEWuDu24V7d5/6qe2j6qcSCFv++hxdP2RN15Myp3rbP8D2671zznMnsnKAQKMWBLFpbBX+EYLfu3N6rIBTzvfM+GmzWraQ6/xhfF7Rv624SnFEWty6JtdocgIdLErFBlB+zjoYmUZ9zJObLEwL+qqC2XbXbEk6vL8OEiYEJcyiZsAr77tM6LdRweSHJiYGDou+2A/r1XHopaft1/H0WeeTMqda2TCna7VaxtNvDZnj+QeLe07h6EAEWHWSvURKRc3E2WyFAIJnyk1wNgR4uRLw7atirPxHnTNKS/up1YxXqFQ1KGLXaHICHSxKxQZQdvcZdPRT3E6Tfnc2aQ88vIzst34WFIu9PaLup7tN9jyZduTMhWLgdn6p8hNhz0DA6LdjZ//clJ+7u++JermJsaT8sTsrKgbWGf7Wd0xlpRP7H9atLvs019MyvlSV2DCjecLxNMVBgkwYvsQ5q8lbNY07SLLu/CZxlKMHaw3/6ZAWtNfvutrtCNt6DauhLssEW0lol8S0TtE9BYRfaN+fg0RPUlEB+v/BxbrS6FQtA8xYvwCgD83xlwH4JMAvk5E1wN4GMA+Y8x2APvqxwqF4iJFTK63IQBD9fIEEb0DYDOA+wDsqTd7DMDTAB5atD+/IO+/plpJysdfei4pj772smhXytvUSrnCKVF38v33k/LAjTcl5UtukWazQqcVi9MSYJXV+eWmzddcl5SvvvNeUbd/7/9Jyn0kTYe9LI2UqdqxJj94W7T7qKvXjnXLHlGXd0yOtsPgYRwCzBNNi5+RM5F8Gs2SS/jPmiozI7pjE/+cK8tz32gu/gq/J2IwrXcdS9qgI6LLAdwE4AUAG+s/BOd/EDYELlUoFG1G9GInol4A/wjgz4wx44u1Z9c9SET7iWj/yOhoM3NUKBQrgKjFTkRF1Bb6d4wx36+fPkVEg/X6QQDDja41xjxqjNltjNm9ZkD38BSKdmFRnZ1q9B5/A+AdY8xfsaq9AO4H8Ej9/xMxA1rSRtf04deFqkx/PXXS6uLnzk2Ldj0lq/NSbk7U5TusPl9+dX9SnmXmOgAY3P2ppNy9zq+ZCL0xpeRZP9gbbv+sqBodHkrKQ688L+pm56y77/SsnX8XZJrns6/L6zg23/K5pJxnZsW0wWvpumfz/OnNmdDix/PvHUgSUh4dJz+/fOvFz8P32KZSZPu7cEaOiwZNq/NG/m+AGDv77QD+FMAbRPRq/dx/QG2RP05EDwA4CuCrEX0pFIo2IWY3/rfw/zDdtbLTUSgUFwpt8KCr/W6kJN9AQFIub6fZf6Ulcnj/jTdFuwUmwnSVpAmqY96K+IWyLU+8f0C0mzpto9Qu+cQeUbeGjY0AeSEnNiw4Hno33/2lpPzUiaOibvKsVVFyE1awrDoEGN1Fez+GX5app6hkOeu3fPxTrMJPdpDig48km1iJbMshdcjnWRagfA+bGI3fvNYsH2RIm5PzCJCuRI8WkT8g0ER94xWKjEAXu0KREbQv/VOAEy0tRdm2V378lqQ8MS7TLr3+pOV+WzUnvdP6eyzfG+Xsb1ye5E539Zx1IfjwN/9P1M1M2rqN11kvvHyHE0zDCTYc9A5Y4okdd35B1D37+LdtF9OWez6Xk19Tge3250mOdfT5p5Jy1/rBpLx26xXeOaX4AIXHGxP3U6qAH54MUg0a+snWfepEk054wUvE53Q52aPJ96LviH8uTVs8Fpfj9c2uUGQEutgVioxAF7tCkRG0VGc3xkbnEFy9Nifa+ZAvWP141567RV2Vmeief+KHom5ydiwpD/RYT7W+Hkn+0NNrUyWbqvTQO/zrnyXl0Y+OJOWtN8vIuZ4165My5SSrJOXs595y9Q2ibvOO3Un5yP5n7TVVx1RTsX10d0kTY3luLCm/91s735v/+f2iXUcn46xP6co8Pxr8iHP28uaOSw0dy2sRG2IXQEgPD/fg6PPeG9SsXTJE4rI8ogx9sysUGYEudoUiI2ix6c0kpAwm9TtT5a2cqzxwRKgbP8XSHDti1As/2puUp87YUNtVU5OiXd+sFeuLBSmCd/XauokPDyblA6dPiHYbbrDi+Lqrdoi6YrclnsjnpMlux2es9/HRd6x34OjIadGukLN3pNAhv8KubiueTxw/nJSPvymJPrbdfDs78nOoNyuNRpvNYnWBRUbzXePrIpXyOLb/kB7SZEroNMd8uuvAjKKhb3aFIiPQxa5QZAS62BWKjKC1OrsBqufNRo7uIzjZU+QBnJyAkz763VJ3fPIT4rh3dV9SfubHVn8/fvRD0a4wPpGUVzlmuUFmRisU7K0rzEoT3cn9v0zKI0feFXUbPvbJpLxm61Wirm+tdaW97rY7kvL+vf8g2k2XmenQVEQdv3XdbM/h2AtPiWb9g1uT8sAll8EHqTc2R/Toyz+3pC7FMxA1bG24SG9WURUg1iQTchkOkGiIcshd1rMHkG7o1C1OXqFvdoUiI9DFrlBkBK31oINB1St6s9S3ThvOoW6EeOiIsPCLQNuus1zuawdtNNjLz8gUUi/+wqZKLs9IHjsaHUvKCxUbVTewqlu06yxZk9rMsDTLvfeL7yflgas+Jud4i+Wru/pmq4acePc10W5qyJJejE9JFYLfOU7gQbPSxHjotzai78Yv/0tRV+peheXCJ002K8VH9xHKJhUg7AhPKpDG29NN2JQX0GERab5z1IlqvXHoEn2zKxQZgS52hSIjaD0H3Xk+NZcwgbwHXoIDlw7YYV2QNWy8Vf2rk/Id90oCicGtW5Lyr/7vXlF39rTliFtgqsUs47cDgFUsmKansxMSVvU4tv83omaUcdJd8xk7r513f1m0e/57jyXlmbJUNbgYX67YsUqON+DcEesBePj5X4q6q++wY+cL/BEJCdBxrnbN0lFHj5QK6vH1twSCCmpYbNRpVB+x8T5Bb0B3iUTcV32zKxQZgS52hSIj0MWuUGQEbeCNb+zpE45B4gqP/X0KOxg55juu6zN929XVrt5ho9QGmEcbAPzqJz9KykfffSspT8+WRbvuCWsO6+uRZrnuTktw2dMhyS7LjLP+d09YvfySnZ8S7S7daUk3Dz33K1G3ULU6/DwjuZgryK+6VLQ6/FFn76Cjx3LPX/5xS8yRL8r5SotRYA8mUk+PTcW8pMi5yE5SpJvetnG6faiPoOmwyXsVc9mib3Yi6iSiF4noNSJ6i4j+sn5+DRE9SUQH6/81a6NCcREjRoyfA3CnMWYngF0A7iWiTwJ4GMA+Y8x2APvqxwqF4iJFTK43A+C8+1Wx/mcA3AdgT/38YwCeBvDQ4v0lJc/5BlxbxH6TQiY6ZopzySsMS6FkAsRnXDVYt2mTqPvCv/jjpPzSr6256ne/+rVoNzFqg2kmJ2dE3YYB6522atM6UddVsoNPs+Caoy89LdrNd61JyuW8JMCozs/acsV+trmc5NGvdtkgn56C9EQ88qzlrjMVa1bcduudoh1Py5XCiojuPoOb/9lxIZ6CYERO3CyC/TeNxmmp0gFhgS4iVKDY/Oz5egbXYQBPGmNeALDRGDNUG8cMAfDnN1YoFG1H1GI3xlSMMbsAbAFwKxHtWOSSBET0IBHtJ6L9o8y3XKFQtBZLMr0ZY8ZQE9fvBXCKiAYBoP5/2HPNo8aY3caY3QMD/cuarEKhaB6L6uxEtB7AvDFmjIi6ANwN4L8C2AvgfgCP1P8/sVhfxrD0w6Ggo5RNjUUr8Tpyf6vIU4ZQxoU+n4qw42PJuk6m53767s8n5U2bt4h2T33fRrbNnpW/gZx8Y25uVtTlc9a0VcxzM5fUqWfHbJ+jp0dE3bbNVptav8aaDhcWpEsv/2QdTlppsIi+I4z0omtgo2g2eM2NSTnMwx5knISvsinijJBJKmAqlIfxZPmxtJWcsML18ibf7TFu7+Sriro7MXb2QQCPEVEeNUngcWPMj4noOQCPE9EDAI4C+GpEXwqFok2I2Y1/HcBNDc6fBXBX+gqFQnExovUedF55I8AxxuQcwz3oAp52qbQ8nsil9HzsiTTRBvO8Y2mfr7pepnHqZJFuL/xERs7NjZxMyqPj46JuctqK0zmudjjzYEPj0o39oq7EOOU3rbGecHkn7fPIuCWzmJmX/ReLlvRidtqaEQ/8+qeiXd+GS5Jyz4A0I8YiZHrzpjtagsMcebjr3GdHmn7l/RBtnedKmvZ8FfJEMEItxLUXa2L0QH3jFYqMQBe7QpERtD79UyKSupS8gcgJvn0pdsgdkYoCYjyjgc4xVcAV2YTInGLr9XjhOe02b7siKd/zx38q6t561gaufPDq70RdefxcUq6wIBZU5QCXbbG77JdulV5+J0+eScpjY2NJuatDkmh0s7RRExPnRB3PhpsjWy47loWjrzyXlK/d8yVRx9WcpYds1PvwPBNB8ofIXWpXfeBjhfnpXO9ObuVhlpzUPPwMGOSR/5fG17e4IK9vdoUiI9DFrlBkBLrYFYqMoA2mt0r9v/M7I9SzgCcS15FSejnvU/Yv9HnuiZRzTTCcv97pv8qPK6yda6Kzdb39a0TN7s9b8shNl18p6l7+meVynxi2aZrXDvSKdjk2j7OnR+XIbCpjjERjpiCj3kqMiKLDIbYYm7Bmud5eO3YxL+/H8HuvJ+XNO3aLur4Nlptfat7NMceLrEipSv914rsWvPHxaCayLZpUctErWR9Ra8Q/kr7ZFYqMQBe7QpERtDb9kzGoJlzmTuqmkHgumjEPupwjqgurnMsbz81yfh47YiY6xyonxHUh7ldkkMnM2NmkXJ4cE3ULc4zMYk6mZNq6zQbUlDbZrLMDfVKMHx6yJrATw2dEXYF5702z9FUdBckfR1V7/9dvkFQE/GOfYyL9QH+faFeZsXUf/E6m0dpxzx8k5VxOctZzBMkrPFEsTVLPL4JAsE7geeTzl7wqoZwGAY5F3zUrAH2zKxQZgS52hSIj0MWuUGQErTW9GZPot+moNH9aXKH/CF1ctqyyupQ+LwgruP7njtaYX752bHXzMiOEPPyC5G6fHTqclAtVySm/MG9NYOREog10W475BRa9tqpPcs8vlC1r97Ghs6JuZHgsKVfZ51zV2yPaVVgeOOooiboy24Po7baEHeQQTBLbdxk68Lqo27rTppwe2CTJPbxIuZhyPTdgNgvo1Cui9gbJHPleEzubyjXY6IoGQ0WNBG/0XahvfbMrFBmBLnaFIiNouQddtS4Ku2I2T+uUzsTMzGZMvHUo4qQDnRuchDyrqjYs106wOkeMJ2PF1rFTHyXlE++8Ktqt77Pmr1XdUkQ+N2Z552ZnpMmur89yyo+emUrKXWOS5KKjw5Jc9PR0ibrT4/a6yRmeCkrekI6SNcWdcfrv7bN9ru63Zr/5OX966DnHjPjRgTeScj8juUhHO8byxvvPxqQrrrXjPHABEoqoWZy/zsNYEXChi/WuS5+P8CwNfBB9sysUGYEudoUiI2itBx2M9ThKBY9w+PnjQnTAIYFLiouNd3lrh/zYmSMT/SbHbABKtSrF8ULe/oYWHZrm+QXbf9khpZgr2516njZqVa+knObif9mhiF63zu7UT5+wnnaTs1IE72YBQLPjMkimbzXbgRfZb6XXY559tpwTUDR0yGa53X7rZ5NyR0mqHUHx2fi++FTLuB59Rh23LjBSqkufJSD1CIeotnl/gbFCYvxKpX9SKBT/9KGLXaHICHSxKxQZQevJK1KFOrj3WygQikevpQgheXduJ433CFJRV8avz4vemCdcMS+jugqMDCLvep2xCLBpJ/3TB0dPJeXytDWhzUxJD7ozo4yUYk7q26tWW/Nd32rrNTfrtJtnLBc5597kmK5cnmYegHnHKzHn35uYHLGfZeKsJeJYd8mlop3xeDYCKTpRdk1zbnH8qtzSFHPPnJoc3O886nDUB6bUBAlI9Ju9nrb5FSL6cf14DRE9SUQH6/8HFutDoVC0D0sR478B4B12/DCAfcaY7QD21Y8VCsVFiigxnoi2APgSgP8C4N/VT98HYE+9/BhqqZwfWrSzusnNBH5nUlkuRSVv5xfBq45ImBPH/mAayRvvr6ssMGKIoryNRX7s2FKKBSvGT05Jc9iR41bc3bzWeq5NO552kzNW/HdFWp6t9ZKNll/+9FnJDT8+ZVWBzrwUwVd3WQ/AAhPx8wXJPc8VA3JUmeqsVUNGTnyYlNc6YryEXzQ1ARK6ULZXnylrSRxxkZa9WAS7iDQBLikYqI7YN/tfA/gLSMV3ozFmCADq/zc0uE6hUFwkWHSxE9GXAQwbY15uZgAiepCI9hPR/jHHB1uhULQOMW/22wF8hYiOAPgugDuJ6G8BnCKiQQCo/x9udLEx5lFjzG5jzO5+h8NMoVC0DjH52b8J4JsAQER7APx7Y8yfENF/A3A/gEfq/59YdDRjdS9K6duR7oQ8Yi2Q14tc4gmPz22KZECQSso+qsxddH7WurPmXZMUI7R0vYILzBS3sCArp2dt/8WSNbfNV2X/VfZZXM56TrDR2WFNbx1FqVPz+7+qR+ri6wes+U58TUVJWjnF7ke5LPcV+LxOf/RBUr7q5ttFuxyFoh35hD3nHaTcV33m0yZ17+a5MDj5Ruzgca6/TvdeLMep5hEA9xDRQQD31I8VCsVFiiU51RhjnkZt1x3GmLMA7lr5KSkUiguBi8aDjouVwRRBvFh1O/GbzXzpfylgenOjvDhv2wIjcqhWpChdmWfXOWatHPM6cyPFenusmFwqWdF6fFp62s2w6Dg4KZk6GY/dLDPRFRzqdj70+tWrRV2B9Vlh97ECKapzshBj3DwA9rqzJ44n5fLMtGhW6pac+D740jiljlOkJR4EvTTdPuKE92BUWvC6OFDQLLdypjeFQvFPHLrYFYqMoOVivE/cCHlBxQo6cifdv1Uve3N2s1kf1ZAYz0T3OSfIZHbOBo+4GVI5QcXYxJSom2djD41Yj7e5WZf7zc5j8yXSl4kTPiws2HkUHOtHH0sTtd6hqp5h180usB33BUdUZ7pAxUmBRexejZ+1QTEjp06IdoOXb2cXufTfFqHgFy4+R2+yu5v2gaYhvpRo/jifGyik2sqbpZ3iAp9zcQo6fbMrFFmBLnaFIiPQxa5QZARt0NkbQ5hWQmmAnBpxFODmFimfAro9H6vqmPaqzCuvygabmnbIHJlHXYdDXsHNeV2O59pHE7af8dOW0NJUpK68lpFSFAry93p83Or6nR22ruKYBwfX9SflXEFqemU2Htcnc44SWWHeegsLct+Cp7GeYybAN37zC9Gub2B9Uu7p6xd1vtTdXpLHWq1z5Hl23IcsImoMaLSbxPVovjEUz0sfO1gcGaW/kb7ZFYqMQBe7QpERtFyM9/HLSSIKv13EBPjAgtzcQsTn3lhuQ96f81tI1g2NOqy5avSc9AojnqnVERcLRdvn5tUys+rpSWvyOjNqw4HzjpdcT5f1yjs3MiLq5pnZrFSynnEVRxUo5plnnJFmsx7G7c7v22xZqgJTM+zY6Z976OXYdzt06A3R7o1nNyblXXf8M1HHvQElD5y8H1z1Cnq7RXCrN4JXVF8hiP5XmCiDQ9/sCkVGoItdocgIdLErFBlBG6LefEo7KwdcGYM5rfzBT04oU+g3jpnoyNXZ7fHqQUucOFOVE56atXrzOsfFtLvDpnDuXC3TOd/eaY/nK9Yk5d6zaeY+OzUjI+LyRdvHQB8jr1gro8v6uq1e3tnhcNtTYxOScfYO5tnxXMCNtMjC4ypsTwEADr/yTFIu9a0Rddfu2p2Uu7j+Dr9bbUjPDWnb/LlaGie7adgqFU3p44YHnIQHca6/6brz+yf+ueqbXaHICHSxKxQZQes96CIsF2lygsZHqa78mYQcET/krRcwyzExfs0mK8ZfdtU1otlW2Gi2/i4pqs9NW7F+el56nRWZaa9YYqmVHDG7v9f2WZ6T/RdY2xIr5xyevAWmXszNOamYeVvBp+fn6a84fHoLFdOoWYroY3Z8LCm/+PMfirqxkbNJ+abbPpuU+/r7RbscS6kVJHUIRVZydcXlnvdf5bRrTocwIvVZ3DzcI5dopRH0za5QZAS62BWKjKB9u/FLcHQSyZoYz5zr4RbgB5DJWcV5J9iFi1FuHaenZmLTdYPrRLvSuO1jvirJ3+aLts+RqbOybpalZOpmX41DIGdYkImbxRXseJoFyZAjxvNgIDewpMBSOXERuerc1Nk5O4/pOemFN8t4+CpcpE9x/tny+PhJUffKUz9KypNnbN32XZ8Q7bZccVVS7uldJep4plmigIrGr4nkQExf6OdRFKpApEgfGsulEJ+frnlcuoQrHPpmVygyAl3sCkVGoItdocgIWqqzGxiY83qvoyf6dGq3LuguJfp0I6NYmavezmD82CWv4AQQc2eGknL59JBoN8PMWlWSBBWT86wPkumUzk2eSco9xn41s24qK8PTUEmdvcxSNnMTmpuiKse94VKsCMzcxu+Hc6/KzHQ4OiU9+bgljvPjpwgwWLRc1THfkbEmzA9fezYpHz/0jmh36fW7kvLVO28VdZsv25aUu7qsFx7lQs9OgPA0ZV2LDFMLsFZyklC+L5Jzn2Fu6pyTZKVT52qkntWKs4fDEJuf/QiACQAVAAvGmN1EtAbAPwC4HMARAH9ojBn19aFQKNqLpYjxnzPG7DLGnHdYfhjAPmPMdgD76scKheIixXLE+PsA7KmXH0MtB9xDwSuMFdvcFDtGZG5yzWEe003A+y0kxnPx3BVNK+zEguPtxb3OpkYtacTEiDShVedZ/zkpqk8wKWtqXnLXTU9a0awMK/4X56VZi8+rXHbEeCZaFxlnfUeHY77jYqzzZfB7ML/AvLsc0XeBieCTszLAhUvFHUXmyef04c6fg6fKAjM3lsdkdvD3X3w6KR9/7y1Rd8n2G5LyNTttYM2WS7eJdl09Nmgo5/LXR0akCBKNgPk4naKKexvy1FtOFmF2D6bG5DM3crqmAi44zwpH7JvdAPg5Eb1MRA/Wz200xgzVJmiGAGzwXq1QKNqO2Df77caYE0S0AcCTRPRu7AD1H4cHAWDD+nWLtFYoFBcKUW92Y8yJ+v9hAD8AcCuAU0Q0CAD1/8Oeax81xuw2xuzuX923MrNWKBRLxqJvdiLqAZAzxkzUy58H8J8B7AVwP4BH6v+fWKwvY0yi57kugxXm5udGV3GTV1XkYnN0moD5zmdSS5nX2LHLtc515RmypI/D81Ifnjpj9amFqrzF42Xu6iqJKvOMh32KfbZSSfbP5zznRM5xt9Vi0c4x7/DLV/i9cs2PrFKQXeZkH2WmH1ac+9jN9gjy7LPMlqU75xzro+Do850Ftt/BJtmRd813LDfdmY9E3eGx00n55PtWIN145XWi3bVMn79s25WijqfPTlt747K9heI4Q27eHPNl+zknJsdF3aHDRwAAc3Ny74QjRozfCOAH9Q9VAPB3xpifEtFLAB4nogcAHAXw1Yi+FApFm7DoYjfGHAaws8H5swDuuhCTUigUK4/WR73Vxb2KI4JzMd4Vn7mXlfC4SonxfpMaF30rQoyX7SohEZ/Lu0Ur2q3ecZts99HRpDw+JsUtMPMapqUX1GzZeqHNMi53mnbMKVwlyct0y7lV1oQ0Pz9jy47HFf9kbiZm/t2ICDCSN4trBr2OqpFjlfPsPs46piHRo/GrVAusnIpJ4xF8rhjMzJtzZ44n5WPnTotmZz58z9Zdf5Oo23nr7Ul5YI3cZBbmwQC3vZxv6kxUO/44TjrPxMHDHwIAZsvSnCvm6q1RKBS/V9DFrlBkBLrYFYqMoA0pm2uKRzB4yE2jLNItNz4POCa7VB+L95eaiGtmYVXc7bPH0eO6BtYm5UtSewL2xLzrBitMWcwUWZGT5OwrXd2SD77EIrumx60J8L1XfiPajZyy+muK7Yax63D3TTdiLZ9jOrVzs2aYmy1383T3B+bZHkwhlebYzquHudx2FOU7qsC+mLxjHuxipJtFxvhTqcrPPH/6WFJ++zfSZeTEkUNJecctnxJ1l3GWnB7rR5Jz5gHhghunz7vP9zwzs87MOZGQSQSl//2tb3aFIiPQxa5QZAStT9lcl2Dc6KecYYQJjikij8Zml4pjZ+Fpi6qOCMStRnzoivNzJ0k0/AQbMhLPbecnhhB9OCI+N/WJ2ZNj1srbry2fc+rYcXe3NcOt+twfiHYfHng1KR89KMkgZqatZx+fopv2eWbGtpuZd+RzGcbITssP3VW0813VXZR1zHzXwUgwHR4OdDLxvChvh1ANxCPnRl3yB2RhRtSNHn47KT8zLIlK3mPkGFddY73yNg5eIufI1KtCXkZCCs56ca/kMzw5Zc2nI2dOiLpKnbTEFf059M2uUGQEutgVioygtWI8WTHTkWBRYHKVG1vAD6tsVzNv5G9VNbRTz3m+Ap52vJ1xRXDOXee5pnbMys5nCXHcVT2efW7/VXZHFlKugnbHlntx5Ytdotk1O+2u8vYdkretKjKtMs68WemF9/brLyflQ+++LepmmYjP71veeb+USlakXd0j+fp6O61YzzfgCykriWlYBqToLrgwXK1DqG/y6exgvH7z45I04tiblont6EEbaLOqX2ak7V9rLTQut32RZfblvO9VxwozPm69MU+ckGL82dO1eZVnpQrCoW92hSIj0MWuUGQEutgVioygpTo7gdKeRXUIWm1HJ+MEgDzCyc09BsG/7VR5zGYhnT3NKd+YGDAdHcf0frcT4aHn6OypWTeeB/euc0kxZVQgN1k63m/MfsVJLgCg1NHF6uwj0tWzWrS79dMDSXnDps2i7pUXf5uURxkhpxvRODpl9wdcj8J1vZ2sbPXaUrc0XXFrm+vlJ54EthHimj2ZZS9lts3n+Hctlf0SOy5PnUvK56ZktOPoCRsJWXVzFFLjNZEiT2F7B5UFea9y9e+dNNebQqHQxa5QZARtCISpwf2VMVxUT6XmseKMYVfmXAmZXZYSzz3kFW4kDBfvXIGQPKpASlAXaoKfJ88l8DAe01soDdWCE1nCg2m4iO8SfXCx3lWtCtwjjYn4HY57Guen27D5ClG3+3Yrdr/1ygtJ+dSJY6Jdlc1xal5+zvlxS+YxyYJ1BmZKot3qLivW95TkI13Mce809pnzruchT5XlpNlm95RyfrWpINKKuSoaU6+cZ8KX+qzqqHll3oczj/Nfp7t0OPTNrlBkBLrYFYqMQBe7QpERtFhnN0lEWyh9lgtfW9cV1RlKHgo92k8qGZsHLkRa6TPzuW1dPdrXZ3qOtjJNzsnrGpvhAKmzp+bIUwOLvHLy3SDSQDt6aKGzPylfeYPlZKe8NPOd/ugI60LuP3DTKtfnq9OSG32WRdz1dcr+V5XscanII+ccogy2L+SaKYsdjH/fmWOFhU1yHn3XxTmUL87n5l11+iixiEZTdV3Fa9epzq5QKHSxKxRZQds46NKOZcxEEkiWw+vcOH0uArnpiHwpn0JivBN0JMklGnMz1NoFou9ExukmVQ2RDssVfZmIz015qShATgjiiIS+Dxeah+sEZlh6rFK39bTbcuXHRDtuAhs7+aGoI5YOi4unrp/hXJWb76RnGefr4zUlJx0WN7Y52aUEr51jlRPoZOm5QyQSIYj0Zo6KlmPc/G7dea9KlxRGXB8zASLqJ6LvEdG7RPQOEd1GRGuI6EkiOlj/P7B4TwqFol2IFeP/O4CfGmOuRS0V1DsAHgawzxizHcC++rFCobhIEZPFtQ/AHQD+FQAYY8oAykR0H4A99WaPAXgawEOhvgzSoqCoTIqOyMlFU77TjYCoHtoFNwHxNkAzHUtHLY5TUnzk2ELV8IvqPnGuVuYivZyHSFXkpHUy1NjrjFzOPybe5pwd7Bx7jxRYqqxV/etFuy1X7mzYDgDGht63ByxTqyOBi53uBed+z7H7k2PWg+q8P5VVySG5E9+78/wWGR8gb0huplYmXqfulRC9Gz/rLlw19Xw2XH9W2bg3+xUATgP430T0ChH9r3rq5o3GmKHapMwQgA0RfSkUijYhZrEXAHwcwP80xtwEYApLENmJ6EEi2k9E+8+dm2hymgqFYrmIWezHARw3xpyPZvgeaov/FBENAkD9/3Cji40xjxpjdhtjdq9evapRE4VC0QLE5Gc/SUTHiOgaY8wB1HKyv13/ux/AI/X/Tyw6mgHTYV2SRr+CEu39FjB5+eoClrGUJ5XQw0R6Xgn+C5pSlVkXrpmkWm2sH6fnIa6SA3hCqEwq0sof9SZ7t53k3HeD4XsCjkcXJ3pk96pQkMQTvX2WmHHLFdIs19llU1sNH7VkjuVZKSEKHT71GLE9DHZvuory0ecEEvMp10w+/7yvSpjscs7+Bv+u3bTSXM0mZgQMed2VnWjHznrjkOkt1s7+bwF8h4g6ABwG8K9Re6YfJ6IHABwF8NXIvhQKRRsQtdiNMa8C2N2g6q4VnY1CobhgaLkHnZ/ygbcJsFJEms1C1G+iZzczqZCp/CYYzh0QmyYKkCYTcsxm3ASWY8wcRC6vGPc2dNHYpFapOMK/MBP5epBIewNyzj9HbPV4vLmiab5gH8Hu3j5Rt+mya5NyJ6s7cfhN0W5m7HRSXnDUGi6688ELeTnfPOe2dyR1nquA3EpBmGL7LDhueKGgIa5iEflVBsGvl5dZaKsL1dT1LtQ3XqHICHSxKxQZgS52hSIjaH3Um9fExvXy1EWesr/rtCmvsamMXBID9vtHjknKiDxzfCxXH+ZlR5fl7puOmyo/5qYbl1ecH6c49jmRJNP150lGg1UDt1TuQUhjpGzI9k/cvHjeq1ydkn1O536XSpa/fu3GS+35zl7R7sP3XknK48PHRZ2IAhTEpe798O/3dApzqZxjB3t+CoxcIuf49EqTmPN98hp2UHR1dk6e6eYQpJVxl1UoFL8H0MWuUGQE1GyQfVODEZ0G8CGAdQDOtGxgP3QeEjoPiYthHkudw2XGmPWNKlq62JNBifYbYxo56eg8dB46jws0BxXjFYqMQBe7QpERtGuxP9qmcV3oPCR0HhIXwzxWbA5t0dkVCkXroWK8QpERtHSxE9G9RHSAiA4RUcvYaInoW0Q0TERvsnMtp8Imoq1E9Ms6HfdbRPSNdsyFiDqJ6EUieq0+j79sxzzYfPJ1fsMft2seRHSEiN4goleJaH8b53HBaNtbttiJKA/gfwD4AoDrAXyNiK5v0fDfBnCvc64dVNgLAP7cGHMdgE8C+Hr9HrR6LnMA7jTG7ASwC8C9RPTJNszjPL6BGj35ebRrHp8zxuxipq52zOPC0bYbY1ryB+A2AD9jx98E8M0Wjn85gDfZ8QEAg/XyIIADrZoLm8MTAO5p51wAdAP4HYBPtGMeALbUH+A7Afy4Xd8NgCMA1jnnWjoPAH0APkB9L22l59FKMX4zgGPs+Hj9XLvQVipsIrocwE0AXmjHXOqi86uoEYU+aWqEou24J38N4C8gOS7aMQ8D4OdE9DIRPdimeVxQ2vZWLvZG4TiZNAUQUS+AfwTwZ8aY8XbMwRhTMcbsQu3NeisR7Wj1HIjoywCGjTEvt3rsBrjdGPNx1NTMrxPRHW2Yw7Jo2xdDKxf7cQBb2fEWACdaOL6LKCrslQYRFVFb6N8xxny/nXMBAGPMGGrZfO5twzxuB/AVIjoC4LsA7iSiv23DPGCMOVH/PwzgBwBubcM8lkXbvhhaudhfArCdiLbVWWr/CMDeFo7vYi9qFNhALBX2MkG1YOO/AfCOMeav2jUXIlpPRP31cheAuwG82+p5GGO+aYzZYoy5HLXn4SljzJ+0eh5E1ENEq86XAXwewJutnocx5iSAY0R0Tf3Uedr2lZnHhd74cDYavgjgPQDvA/iPLRz37wEMAZhH7dfzAQBrUdsYOlj/v6YF8/g0aqrL6wBerf99sdVzAXAjgFfq83gTwH+qn2/5PWFz2gO7Qdfq+3EFgNfqf2+dfzbb9IzsArC//t38EMDASs1DPegUioxAPegUioxAF7tCkRHoYlcoMgJd7ApFRqCLXaHICHSxKxQZgS52hSIj0MWuUGQE/x+S1YBYENYLQQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of a picture\n",
    "index = 6\n",
    "plt.imshow(train_set_x_orig[index])\n",
    "print(\"y = \" + str(np.squeeze(train_set_y_orig[:, index])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can reshape and 'standardize' dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 3, 64, 64)\n",
      "Y_train shape: (1080,)\n",
      "X_test shape: (120, 3, 64, 64)\n",
      "Y_test shape: (120,)\n"
     ]
    }
   ],
   "source": [
    "train_set_x = np.reshape(train_set_x_orig, (1080, 3, 64, 64))/255.\n",
    "test_set_x = np.reshape(test_set_x_orig, (120, 3, 64, 64))/255.\n",
    "train_set_y = np.reshape(train_set_y_orig, -1).T\n",
    "test_set_y = np.reshape(test_set_y_orig, -1).T\n",
    "\n",
    "print(\"number of training examples = \" + str(train_set_x.shape[0]))\n",
    "print(\"number of test examples = \" + str(test_set_x.shape[0]))\n",
    "print(\"X_train shape: \" + str(train_set_x.shape))\n",
    "print(\"Y_train shape: \" + str(train_set_y.shape))\n",
    "print(\"X_test shape: \" + str(test_set_x.shape))\n",
    "print(\"Y_test shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will also train your model with mini-batches to speed up parameter training process.\n",
    "\n",
    "Here's helper function to split data into batches. This function will be implemented with numpy, and we will retrieve these batches later during training. So, PyTorch Tensors for training will be created after obtaining data with this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size=64, seed=0):\n",
    "    \"\"\"\n",
    "    Creates a list of random minibatches from (X, Y)\n",
    "\n",
    "    Arguments:\n",
    "    X -- input data, of shape (input size, number of examples) (m, Hi, Wi, Ci)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) (m, n_y)\n",
    "    mini_batch_size - size of the mini-batches, integer\n",
    "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
    "\n",
    "    Returns:\n",
    "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
    "    \"\"\"\n",
    "\n",
    "    m = X.shape[0]                  # number of training examples\n",
    "    mini_batches = []\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[permutation, :, :, :]\n",
    "    shuffled_Y = Y[permutation]\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size)  # number of mini batches of size mini_batch_size in your partitionning\n",
    "    for k in range(0, num_complete_minibatches):\n",
    "        mini_batch_X = shuffled_X[k * mini_batch_size: k * mini_batch_size + mini_batch_size, :, :, :]\n",
    "        mini_batch_Y = shuffled_Y[k * mini_batch_size: k * mini_batch_size + mini_batch_size]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "\n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size: m, :, :, :]\n",
    "        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size: m]\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "\n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create Tensors for testing.\n",
    "\n",
    "**Hint**\n",
    "\n",
    "In previous week assignment and exercise Tensor type of input `x` and output `y` was the same, since binary cross-entropy function expects `FloatTensor` as target output `y`. In this week exercise and assignment we will use cross-entropy cost function, because number of classes in the SIGNS dataset is more than 2. This function expects `LongTensor` as target output `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.tensor(test_set_x, device=device, dtype=dtype, requires_grad=False)\n",
    "Y_test = torch.tensor(test_set_y, device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "### Calculate padding\n",
    "\n",
    "As you can see in the exercise 3, padding size is hard coded in the model class. This might be very inconvenient during hyper-parameter fine-tuning.\n",
    "\n",
    "Define function `calculate_padding()` taking into account kernel size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_padding(kernel_size):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    kernel_size -- int, size of CNN kernel\n",
    "    Returns:\n",
    "    padding_size -- int, number of zeros to pad input.\n",
    "    \"\"\"\n",
    "\n",
    "    # Your code here !!!\n",
    "    padding_size = (kernel_size - 1) // 2\n",
    "\n",
    "    return padding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding for kernel size = 11 is 5\n"
     ]
    }
   ],
   "source": [
    "print('Padding for kernel size = 11 is {}'.format(calculate_padding(11)))\n",
    "# Expected output: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "### Calculate the size of the last Linear layer\n",
    "\n",
    "Define function `output_layer_size()` given input_shape and list of strides used in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_layer_size(input_shape, strides, last_filter):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    input_shape -- list of integers containing height and width of image\n",
    "    strides -- list of integers containing stride used in the model\n",
    "    last_filter -- int, number of output channels in the last Conv layer\n",
    "    Returns:\n",
    "    output_size -- int, size of input to the Linear layer\n",
    "    \"\"\"\n",
    "\n",
    "    # Your code here !!!\n",
    "    #output_size = (((input_shape[0]*input_shape[1]) - last_filter + (calculate_padding(last_filter) * 2)) / (strides[0]*strides[1])) + 1\n",
    "    \n",
    "    output_W = (input_shape[0] / strides[0]) \n",
    "    output_H = (input_shape[1] / strides[1])\n",
    "    \n",
    "    output_size = output_W * output_H * last_filter / 4\n",
    "    \n",
    "    return int(output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output size of Conv model: 784\n"
     ]
    }
   ],
   "source": [
    "print('Output size of Conv model: {}'.format(output_layer_size([28, 28], [2, 2], 16)))\n",
    "# Expected output: 784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "### Create improved Conv model\n",
    "\n",
    "Here you need to create a class to defined improved Conv model. Your class should have similar structure as the one we created during exercise. \n",
    "\n",
    "Use functions we created in **Problem 1** and **Problem 2** to obtain correct codding and size of Linear output layer.\n",
    "\n",
    "This class will contain three layers:\n",
    "1. 2D convolutional layer `Conv2d` with `ReLu` activation function and [Batch Normalization](https://pytorch.org/docs/master/nn.html#normalization-layers), expects any kernel size,\n",
    "2. 2D convolutional layer `Conv2d` with `ReLu` activation function and [Batch Normalization](https://pytorch.org/docs/master/nn.html#normalization-layers), expects any kernel size,\n",
    "3. `Linear` layer without activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, image_shape, filters, kernels, strides, n_out):\n",
    "        super(CNN, self).__init__()\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        image_shape: python list containing shape of input image [channel, height, width]\n",
    "        filters: python list of integers, defining the number of filters in the Conv layers\n",
    "        kernels: python list of integers, defining kernel height and width\n",
    "        strides: python list of integers, defining stride for each Conv layer\n",
    "        n_out: number of output classes\n",
    "        \n",
    "        \"\"\"\n",
    "        # Your code here !!!\n",
    "        self.conv1 = nn.Sequential(                  # input shape (3, 64, 64)\n",
    "                    nn.Conv2d(\n",
    "                        in_channels=image_shape[0],  # input channels = 3\n",
    "                        out_channels=filters[0],     # number of output filters = 8\n",
    "                        kernel_size=kernels[0],      # kernel size = 3\n",
    "                        stride=strides[0],           # filter movement/step = 2\n",
    "                        padding=calculate_padding(kernels[0]),                   # if want same width and length of this image after con2d\n",
    "                        ),                           # output shape (8, 32, 32)\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm2d(filters[0]),)                      # activation\n",
    "\n",
    "        self.conv2 = nn.Sequential(                 # input shape (8, 32, 32)\n",
    "                    nn.Conv2d(filters[0], filters[1],\n",
    "                              kernels[1], strides[1],\n",
    "                              padding=calculate_padding(kernels[1])),           # output shape (16, 16, 16)\n",
    "                    nn.ReLU(),\n",
    "                    nn.BatchNorm2d(filters[1]),)                     # activation\n",
    "\n",
    "        self.out = nn.Linear(output_layer_size([image_shape[1], image_shape[2]], [strides[0], strides[1]], filters[1]), n_out)   # fully connected layer, output 6 classes\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can check your model by passing hyper-parameters to its class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(8, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (out): Linear(in_features=8192, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Declare hyper-parameters\n",
    "input_shape = train_set_x.shape\n",
    "filters = [8, 32]\n",
    "kernels = [5, 3]\n",
    "strides = [2, 2]\n",
    "n_out = int(Y_test.max().item()) + 1\n",
    "\n",
    "# Define model\n",
    "model = CNN(input_shape[1:], filters, kernels, strides, n_out)\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "print(model)\n",
    "# Expected output: CNN(conv1: Sequential(0:..., 1:..., 2:...),\n",
    "#                      conv2: Sequential(0:..., 1:..., 2:...), out: Linear...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define loss function and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define training loop**\n",
    "\n",
    "Now everything is ready to define our training loop using `model`, `loss` and `optimizer` created above. We don't need to pass those as parameters of train function, since they are declared as part of PyTorch computational Graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_x, train_y, X_test, Y_test, minibatch_size=64, num_epochs=20, seed=3):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    train_x -- numpy.array, training input,\n",
    "    train_y -- numpy.array, training output target,\n",
    "    X_test -- Tensor, test input,\n",
    "    Y_test -- Tensor, test output target,\n",
    "    minibatch_size -- int, number of training samples per batch,\n",
    "    num_epochs -- int, number of training epochs,\n",
    "    seed -- int, seed of random number\n",
    "    \"\"\"\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        seed = seed + 1\n",
    "        minibatches = random_mini_batches(train_x, train_y, minibatch_size, seed)\n",
    "\n",
    "        for step, (minibatch_x, minibatch_y) in enumerate(minibatches):\n",
    "            x = torch.tensor(minibatch_x, device=device, dtype=dtype, requires_grad=False)\n",
    "            y = torch.LongTensor(minibatch_y, device=device)\n",
    "            output = model(x)               # cnn output\n",
    "            loss = loss_func(output, y)     # cross entropy loss\n",
    "            optimizer.zero_grad()           # clear gradients for this training step\n",
    "            loss.backward()                 # backpropagation, compute gradients\n",
    "            optimizer.step()                # apply gradients\n",
    "\n",
    "        print('Epoch: ', epoch+1, '| train loss: %.4f' % loss.data.cpu().numpy())\n",
    "\n",
    "    test_output = model(X_test)\n",
    "    train_output = model(torch.tensor(train_x, dtype=dtype, device=device))\n",
    "    pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "    pred_train_y = torch.max(train_output, 1)[1].data.squeeze()\n",
    "    accuracy_test = float(sum(pred_y == Y_test)) / float(Y_test.size(0)) * 100\n",
    "    accuracy_train = float(sum(pred_train_y.cpu().numpy() == train_y)) / float(train_y.shape[0]) * 100\n",
    "    print('\\nTrain accuracy: %.1f\\n' % accuracy_train, 'Test accuracy: %.1f' % accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 | train loss: 1.8376\n",
      "Epoch:  2 | train loss: 1.5376\n",
      "Epoch:  3 | train loss: 0.6616\n",
      "Epoch:  4 | train loss: 0.1033\n",
      "Epoch:  5 | train loss: 0.0621\n",
      "Epoch:  6 | train loss: 0.0311\n",
      "Epoch:  7 | train loss: 0.0413\n",
      "Epoch:  8 | train loss: 0.0025\n",
      "Epoch:  9 | train loss: 0.0041\n",
      "Epoch:  10 | train loss: 0.0019\n",
      "Epoch:  11 | train loss: 0.0015\n",
      "Epoch:  12 | train loss: 0.0017\n",
      "Epoch:  13 | train loss: 0.0013\n",
      "Epoch:  14 | train loss: 0.0013\n",
      "Epoch:  15 | train loss: 0.0012\n",
      "Epoch:  16 | train loss: 0.0009\n",
      "Epoch:  17 | train loss: 0.0005\n",
      "Epoch:  18 | train loss: 0.0010\n",
      "Epoch:  19 | train loss: 0.0006\n",
      "Epoch:  20 | train loss: 0.0009\n",
      "\n",
      "Train accuracy: 100.0\n",
      " Test accuracy: 85.0\n"
     ]
    }
   ],
   "source": [
    "train(train_set_x, train_set_y, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
